{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import os\n",
    "os.environ['MUJOCO_GL'] = 'egl'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from hydra.core.hydra_config import HydraConfig\n",
    "from omegaconf import OmegaConf\n",
    "from huggingface_hub import HfFileSystem\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "import gym\n",
    "import h5py\n",
    "import imageio\n",
    "import numpy as np\n",
    "import torch\n",
    "from termcolor import colored\n",
    "\n",
    "from common.buffer import Buffer\n",
    "from common.parser import parse_cfg\n",
    "from common.seed import set_seed\n",
    "from envs import make_env\n",
    "from tdmpc2 import TDMPC2\n",
    "from collections import defaultdict\n",
    "from envs.wrappers.pixels import PixelWrapper\n",
    "\n",
    "from tensordict import TensorDict\n",
    "from mujoco import mjtVisFlag\n",
    "from IPython.display import Video\n",
    "from envs.myosuite import MYOSUITE_TASKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobomimicBuffer(Buffer):\n",
    "    def get_episode(self, episode_id):\n",
    "        \"\"\"Retrieve a TensorDict for a specific episode.\"\"\"\n",
    "        return self._buffer.storage[self._buffer.storage['episode'] == episode_id]\n",
    "\n",
    "    def save_hdf5(self, path): \n",
    "        with h5py.File(path, 'w') as f:\n",
    "            for episode_id in range(self.num_eps):\n",
    "                episode_td = self.get_episode(episode_id)\n",
    "                # Convert TensorDict to numpy and save to HDF5\n",
    "                f[\"data/demo_{ep}\"].attrs[\"num_samples\"] = len(episode_td)\n",
    "                for key, value in episode_td.items():\n",
    "                    if isinstance(value, dict):\n",
    "                        for sub_key, sub_value in value.items():\n",
    "                            f.create_dataset(f'data/demo_{episode_id}/{key}/{sub_key}', data=sub_value.cpu().numpy())\n",
    "                    else:\n",
    "                        f.create_dataset(f'data/demo_{episode_id}/{key}', data=value.cpu().numpy())\n",
    "                    f.create_dataset(f'data/demo_{episode_id}/{key}', data=value.cpu().numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mTask: myo-key-turn\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-key-turn-1.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mEvaluating agent on myo-key-turn:\u001b[0m\n",
      "Buffer capacity: 1,000\n",
      "Storage required: 0.44 GB\n",
      "Using CUDA memory for storage.\n",
      "\u001b[33m  myo-key-turn          \tR: 1217.1  \tS: 1.00\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "buffer = evaluate(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"test.hdf5\", 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 group \"/data\" (0 members)>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.create_group('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ep0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep0 = buffer._buffer.storage[buffer._buffer.storage['episode']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for key in ep0['obs'].keys():\n",
    "    f.create_dataset(f'demo_0/obs/{key}', data=ep0['obs'][key].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('obs', TensorDict(\n",
       "    fields={\n",
       "        fixed_camera: Tensor(shape=torch.Size([91, 384, 384, 3]), device=cuda:0, dtype=torch.uint8, is_shared=True),\n",
       "        success: Tensor(shape=torch.Size([91]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "        vec_obs: Tensor(shape=torch.Size([91, 93]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
       "    batch_size=torch.Size([91]),\n",
       "    device=cuda,\n",
       "    is_shared=True)), ('reward', tensor([ 5.3710,  5.5485,  5.7160,  5.8861,  6.0586,  6.2297,  6.3981,  6.5738,\n",
       "         6.7718, 10.9458, 11.1110, 11.2819, 11.4624, 11.6285, 11.7529, 11.8715,\n",
       "        11.9860, 12.1239, 12.2574, 12.3893, 12.5116, 12.6253, 12.7352, 12.8283,\n",
       "        12.9650, 13.1114, 13.2290, 13.3091, 13.3812, 13.4566, 13.5617, 13.6425,\n",
       "        13.7482, 13.8462, 13.8774, 14.0281, 14.2355, 14.3572, 14.4510, 14.5371,\n",
       "        14.6208, 14.6831, 14.7062, 14.7006, 14.6963, 14.7335, 14.7507, 14.7575,\n",
       "        14.7608, 14.7694, 14.7797, 14.7784, 14.7854, 14.8055, 14.8055, 14.8007,\n",
       "        14.7968, 14.7893, 14.7819, 14.7834, 14.7780, 14.7739, 14.7660, 14.7629,\n",
       "        14.7529, 14.7490, 14.7496, 14.7575, 14.7613, 14.7827, 14.7842, 14.8005,\n",
       "        14.8002, 14.7903, 14.7891, 14.7979, 14.7798, 14.7906, 14.7865, 14.7876,\n",
       "        14.7797, 14.7637, 14.7539, 14.7546, 14.7586, 14.7626, 14.7818, 14.7878,\n",
       "        14.7842, 14.7794, 14.7818], device='cuda:0')), ('action', tensor([[-0.3426, -0.2203, -0.9693,  ...,  0.5204, -0.7167, -0.3774],\n",
       "        [-0.4686, -0.8652, -0.5229,  ..., -0.3798, -0.2254, -0.4933],\n",
       "        [-0.6178, -0.9090,  0.8675,  ...,  0.7376, -0.3823,  0.7832],\n",
       "        ...,\n",
       "        [-0.3459,  0.7556, -0.5733,  ..., -0.5858, -0.9319, -0.2544],\n",
       "        [-0.8627,  0.3933, -0.3559,  ..., -0.2989,  0.6216,  0.1224],\n",
       "        [ 0.0196,  0.5150, -0.1612,  ..., -0.7601,  0.0379, -0.1103]],\n",
       "       device='cuda:0')), ('episode', tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       device='cuda:0'))])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ep0.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        action: Tensor(shape=torch.Size([91, 39]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "        episode: Tensor(shape=torch.Size([91]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
       "        obs: TensorDict(\n",
       "            fields={\n",
       "                fixed_camera: Tensor(shape=torch.Size([91, 384, 384, 3]), device=cuda:0, dtype=torch.uint8, is_shared=True),\n",
       "                success: Tensor(shape=torch.Size([91]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "                vec_obs: Tensor(shape=torch.Size([91, 93]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
       "            batch_size=torch.Size([91]),\n",
       "            device=cuda,\n",
       "            is_shared=True),\n",
       "        reward: Tensor(shape=torch.Size([91]), device=cuda:0, dtype=torch.float32, is_shared=True)},\n",
       "    batch_size=torch.Size([91]),\n",
       "    device=cuda,\n",
       "    is_shared=True)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer._buffer.storage[buffer._buffer.storage['episode'] == 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LazyTensorStorage' object has no attribute 'index_select'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbuffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_hdf5\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m, in \u001b[0;36mRobomimicBuffer.save_hdf5\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m episode_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_eps):\n\u001b[0;32m---> 10\u001b[0m         episode_td \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_episode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepisode_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;66;03m# Convert TensorDict to numpy and save to HDF5\u001b[39;00m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m episode_td\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m, in \u001b[0;36mRobomimicBuffer.get_episode\u001b[0;34m(self, episode_id)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Retrieve a TensorDict for a specific episode.\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m indices \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer\u001b[38;5;241m.\u001b[39mstorage[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepisode\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m episode_id)\u001b[38;5;241m.\u001b[39mnonzero(as_tuple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_select\u001b[49m(\u001b[38;5;241m0\u001b[39m, indices)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LazyTensorStorage' object has no attribute 'index_select'"
     ]
    }
   ],
   "source": [
    "buffer.save_hdf5('test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_td(obs, action, reward=None):\n",
    "    \"\"\"Creates a TensorDict for a new episode.\"\"\"\n",
    "    if isinstance(obs, dict):\n",
    "        obs = TensorDict(obs, batch_size=(), device='cpu')\n",
    "    else:\n",
    "        obs = obs.unsqueeze(0).cpu()\n",
    "    if reward is None:\n",
    "        reward = torch.tensor(float('nan'))\n",
    "    td = TensorDict(dict(\n",
    "        obs=obs.unsqueeze(0),\n",
    "        action=action.unsqueeze(0),\n",
    "        reward=torch.tensor(reward).unsqueeze(0),\n",
    "    ), batch_size=(1,))\n",
    "    return td\n",
    "\n",
    "\n",
    "def evaluate(cfg): \n",
    "    success_only = cfg.success_only\n",
    "    assert torch.cuda.is_available()\n",
    "    assert cfg.eval_episodes > 0, 'Must evaluate at least 1 episode.'\n",
    "    cfg = parse_cfg(cfg)\n",
    "    set_seed(cfg.seed)\n",
    "    print(colored(f'Task: {cfg.task}', 'blue', attrs=['bold']))\n",
    "    print(colored(f'Model size: {cfg.get(\"model_size\", \"default\")}', 'blue', attrs=['bold']))\n",
    "    print(colored(f'Checkpoint: {cfg.checkpoint}', 'blue', attrs=['bold']))\n",
    "    if not cfg.multitask and ('mt80' in cfg.checkpoint or 'mt30' in cfg.checkpoint):\n",
    "        print(colored('Warning: single-task evaluation of multi-task models is not currently supported.', 'red', attrs=['bold']))\n",
    "        print(colored('To evaluate a multi-task model, use task=mt80 or task=mt30.', 'red', attrs=['bold']))\n",
    "\n",
    "    # Make environment\n",
    "    env = make_env(cfg)\n",
    "    buffer = RobomimicBuffer(cfg)\n",
    "\n",
    "    # Load agent\n",
    "    agent = TDMPC2(cfg)\n",
    "    assert os.path.exists(cfg.checkpoint), f'Checkpoint {cfg.checkpoint} not found! Must be a valid filepath.'\n",
    "    agent.load(cfg.checkpoint)\n",
    "    \n",
    "    # Evaluate\n",
    "    if cfg.multitask:\n",
    "        print(colored(f'Evaluating agent on {len(cfg.tasks)} tasks:', 'yellow', attrs=['bold']))\n",
    "    else:\n",
    "        print(colored(f'Evaluating agent on {cfg.task}:', 'yellow', attrs=['bold']))\n",
    "    if cfg.save_video:\n",
    "        video_dir = os.path.join(cfg.work_dir, 'videos')\n",
    "        os.makedirs(video_dir, exist_ok=True)\n",
    "    scores = []\n",
    "    tasks = cfg.tasks if cfg.multitask else [cfg.task]\n",
    "    for task_idx, task in enumerate(tasks):\n",
    "        if not cfg.multitask:\n",
    "            task_idx = None\n",
    "        ep_rewards, ep_successes = [], []\n",
    "        for i in range(cfg.eval_episodes):\n",
    "            obs, done, ep_reward, t = env.reset(task_idx=task_idx), False, 0, 0\n",
    "            obs_dict = {\"vec_obs\": obs,  \"success\": False, \"fixed_camera\": env.render()}\n",
    "            _tds = [to_td(obs_dict, torch.zeros_like(env.rand_act()), ep_reward)]\n",
    "            if cfg.save_video:\n",
    "                frames = [env.render()]\n",
    "            while not done:\n",
    "                action = agent.act(obs, t0=t==0, task=task_idx)\n",
    "                obs, reward, done, info = env.step(action)\n",
    "                obs_dict = {\"vec_obs\": obs,  \"success\": np.array(info[\"solved\"], dtype=bool), \"fixed_camera\": env.render()}\n",
    "                _tds.append(to_td(obs_dict, action.flatten(), reward))\n",
    "                ep_reward += reward\n",
    "                t += 1\n",
    "                if cfg.save_video:\n",
    "                    frames.append(env.render())\n",
    "            \n",
    "            if success_only and info[\"success\"] or not success_only:\n",
    "                buffer.add(torch.cat(_tds))\n",
    "\n",
    "            ep_rewards.append(ep_reward)\n",
    "            ep_successes.append(info['success'])\n",
    "            if cfg.save_video:\n",
    "                imageio.mimsave(\n",
    "                    os.path.join(video_dir, f'{task}-{i}.mp4'), frames, fps=15)\n",
    "        buffer.save(cfg.hdf5_save_path)\n",
    "        ep_rewards = np.mean(ep_rewards)\n",
    "        ep_successes = np.mean(ep_successes)\n",
    "        if cfg.multitask:\n",
    "            scores.append(ep_successes*100 if task.startswith('mw-') else ep_rewards/10)\n",
    "        print(colored(f'  {task:<22}' \\\n",
    "            f'\\tR: {ep_rewards:.01f}  ' \\\n",
    "            f'\\tS: {ep_successes:.02f}', 'yellow'))\n",
    "    if cfg.multitask:\n",
    "        print(colored(f'Normalized score: {np.mean(scores):.02f}', 'yellow', attrs=['bold']))\n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfg.buffer_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded myo-hand-key-turn-1.pt to /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-key-turn-1.pt\n",
      "Downloaded myo-hand-key-turn-2.pt to /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-key-turn-2.pt\n",
      "Downloaded myo-hand-key-turn-3.pt to /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-key-turn-3.pt\n",
      "Downloaded myo-hand-key-turn-hard-1.pt to /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-key-turn-hard-1.pt\n",
      "Downloaded myo-hand-key-turn-hard-2.pt to /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-key-turn-hard-2.pt\n",
      "Downloaded myo-hand-key-turn-hard-3.pt to /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-key-turn-hard-3.pt\n",
      "Downloaded myo-hand-obj-hold-1.pt to /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-obj-hold-1.pt\n",
      "Downloaded myo-hand-obj-hold-2.pt to /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-obj-hold-2.pt\n",
      "Downloaded myo-hand-obj-hold-3.pt to /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-obj-hold-3.pt\n",
      "Downloaded myo-hand-obj-hold-hard-1.pt to /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-obj-hold-hard-1.pt\n",
      "Downloaded myo-hand-obj-hold-hard-2.pt to /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-obj-hold-hard-2.pt\n",
      "Downloaded myo-hand-obj-hold-hard-3.pt to /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-obj-hold-hard-3.pt\n",
      "Downloaded myo-hand-pen-twirl-1.pt to /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-pen-twirl-1.pt\n",
      "Downloaded myo-hand-pen-twirl-2.pt to /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-pen-twirl-2.pt\n",
      "Downloaded myo-hand-pen-twirl-3.pt to /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-pen-twirl-3.pt\n",
      "Downloaded myo-hand-pen-twirl-hard-1.pt to /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-pen-twirl-hard-1.pt\n",
      "Downloaded myo-hand-pen-twirl-hard-2.pt to /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-pen-twirl-hard-2.pt\n",
      "Downloaded myo-hand-pen-twirl-hard-3.pt to /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-pen-twirl-hard-3.pt\n",
      "Downloaded myo-hand-pose-1.pt to /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-pose-1.pt\n",
      "Downloaded myo-hand-pose-2.pt to /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-pose-2.pt\n",
      "Downloaded myo-hand-pose-3.pt to /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-pose-3.pt\n",
      "Downloaded myo-hand-pose-hard-1.pt to /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-pose-hard-1.pt\n",
      "Downloaded myo-hand-pose-hard-2.pt to /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-pose-hard-2.pt\n",
      "Downloaded myo-hand-pose-hard-3.pt to /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-pose-hard-3.pt\n",
      "Downloaded myo-hand-reach-1.pt to /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-reach-1.pt\n",
      "Downloaded myo-hand-reach-2.pt to /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-reach-2.pt\n",
      "Downloaded myo-hand-reach-3.pt to /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-reach-3.pt\n",
      "Downloaded myo-hand-reach-hard-1.pt to /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-reach-hard-1.pt\n",
      "Downloaded myo-hand-reach-hard-2.pt to /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-reach-hard-2.pt\n",
      "Downloaded myo-hand-reach-hard-3.pt to /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-reach-hard-3.pt\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite' -> 'tdmpc2_ckpts/myosuite'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     myo_ckpts\u001b[38;5;241m.\u001b[39mappend(file_path)\n\u001b[1;32m     16\u001b[0m subfolder_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplit(myo_ckpts[\u001b[38;5;241m0\u001b[39m])[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 17\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msymlink\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubfolder_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtdmpc2_ckpts/myosuite\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# subfolder = \"dmcontrol\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# checkpoint_files = ['dog-run-1.pt']\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#     print(f\"Downloaded {file_name} to {file_path}\")\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#     dmcontrol_ckpts.append(file_path)\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite' -> 'tdmpc2_ckpts/myosuite'"
     ]
    }
   ],
   "source": [
    "repo_id = \"nicklashansen/tdmpc2\"\n",
    "subfolder = \"myosuite\"\n",
    "\n",
    "# List of checkpoint filenames to download\n",
    "fs = HfFileSystem()\n",
    "\n",
    "checkpoint_files = map(lambda x: x.split('/')[-1], fs.glob(f\"{repo_id}/myosuite/*.pt\"))\n",
    "\n",
    "myo_ckpts = []\n",
    "# Download each checkpoint\n",
    "for file_name in checkpoint_files:\n",
    "    file_path = hf_hub_download(repo_id, filename=file_name, subfolder=subfolder)\n",
    "    print(f\"Downloaded {file_name} to {file_path}\")\n",
    "    myo_ckpts.append(file_path)\n",
    "\n",
    "subfolder_path = os.path.split(myo_ckpts[0])[0]\n",
    "\n",
    "# subfolder = \"dmcontrol\"\n",
    "\n",
    "# checkpoint_files = ['dog-run-1.pt']\n",
    "\n",
    "# dmcontrol_ckpts = []\n",
    "\n",
    "# for file_name in checkpoint_files:\n",
    "#     file_path = hf_hub_download(repo_id, filename=file_name, subfolder=subfolder)\n",
    "#     print(f\"Downloaded {file_name} to {file_path}\")\n",
    "#     dmcontrol_ckpts.append(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task(x):\n",
    "    x = x.split('/')[-1]\n",
    "    x = '-'.join(['myo'] + x.split('-')[2:-1]).rstrip('.pt')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'myo-key-turn',\n",
       " 'myo-key-turn-hard',\n",
       " 'myo-obj-hold',\n",
       " 'myo-obj-hold-hard',\n",
       " 'myo-pen-twirl',\n",
       " 'myo-pen-twirl-hard',\n",
       " 'myo-pose',\n",
       " 'myo-pose-hard',\n",
       " 'myo-reach',\n",
       " 'myo-reach-hard'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list(map(get_task, myo_ckpts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = myo_ckpts[0]\n",
    "\n",
    "with hydra.initialize(config_path='.'):\n",
    "    cfg = hydra.compose('config.yaml',\n",
    "                        return_hydra_config=True,\n",
    "                        overrides=[f'task={get_task(ckpt)}', \n",
    "                                    f'checkpoint={ckpt}'])\n",
    "    HydraConfig.instance().set_config(cfg)\n",
    "    cfg = parse_cfg(cfg)\n",
    "    cfg.buffer_size = (gym.envs.registry.spec(MYOSUITE_TASKS[cfg.task]).max_episode_steps + 1) * cfg.eval_episodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mTask: myo-key-turn\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-key-turn-1.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mEvaluating agent on myo-key-turn:\u001b[0m\n",
      "\u001b[33m  myo-key-turn          \tR: 1205.6  \tS: 1.00\u001b[0m\n",
      "\u001b[1m\u001b[34mTask: myo-key-turn\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-key-turn-2.pt\u001b[0m\n",
      "\u001b[1m\u001b[33mEvaluating agent on myo-key-turn:\u001b[0m\n",
      "\u001b[33m  myo-key-turn          \tR: 1217.4  \tS: 1.00\u001b[0m\n",
      "\u001b[1m\u001b[34mTask: myo-key-turn\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-key-turn-3.pt\u001b[0m\n",
      "\u001b[1m\u001b[33mEvaluating agent on myo-key-turn:\u001b[0m\n",
      "\u001b[33m  myo-key-turn          \tR: 1236.0  \tS: 1.00\u001b[0m\n",
      "\u001b[1m\u001b[34mTask: myo-key-turn-hard\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-key-turn-hard-1.pt\u001b[0m\n",
      "\u001b[1m\u001b[33mEvaluating agent on myo-key-turn-hard:\u001b[0m\n",
      "\u001b[33m  myo-key-turn-hard     \tR: 1072.6  \tS: 0.00\u001b[0m\n",
      "\u001b[1m\u001b[34mTask: myo-key-turn-hard\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-key-turn-hard-2.pt\u001b[0m\n",
      "\u001b[1m\u001b[33mEvaluating agent on myo-key-turn-hard:\u001b[0m\n",
      "\u001b[33m  myo-key-turn-hard     \tR: 1179.0  \tS: 0.20\u001b[0m\n",
      "\u001b[1m\u001b[34mTask: myo-key-turn-hard\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-key-turn-hard-3.pt\u001b[0m\n",
      "\u001b[1m\u001b[33mEvaluating agent on myo-key-turn-hard:\u001b[0m\n",
      "\u001b[33m  myo-key-turn-hard     \tR: 938.7  \tS: 0.00\u001b[0m\n",
      "\u001b[1m\u001b[34mTask: myo-obj-hold\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-obj-hold-1.pt\u001b[0m\n",
      "\u001b[1m\u001b[33mEvaluating agent on myo-obj-hold:\u001b[0m\n",
      "\u001b[33m  myo-obj-hold          \tR: 771.3  \tS: 1.00\u001b[0m\n",
      "\u001b[1m\u001b[34mTask: myo-obj-hold\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-obj-hold-2.pt\u001b[0m\n",
      "\u001b[1m\u001b[33mEvaluating agent on myo-obj-hold:\u001b[0m\n",
      "\u001b[33m  myo-obj-hold          \tR: 771.5  \tS: 1.00\u001b[0m\n",
      "\u001b[1m\u001b[34mTask: myo-obj-hold\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-obj-hold-3.pt\u001b[0m\n",
      "\u001b[1m\u001b[33mEvaluating agent on myo-obj-hold:\u001b[0m\n",
      "\u001b[33m  myo-obj-hold          \tR: 759.2  \tS: 1.00\u001b[0m\n",
      "\u001b[1m\u001b[34mTask: myo-obj-hold-hard\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-obj-hold-hard-1.pt\u001b[0m\n",
      "\u001b[1m\u001b[33mEvaluating agent on myo-obj-hold-hard:\u001b[0m\n",
      "\u001b[33m  myo-obj-hold-hard     \tR: 615.5  \tS: 0.90\u001b[0m\n",
      "\u001b[1m\u001b[34mTask: myo-obj-hold-hard\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-obj-hold-hard-2.pt\u001b[0m\n",
      "\u001b[1m\u001b[33mEvaluating agent on myo-obj-hold-hard:\u001b[0m\n",
      "\u001b[33m  myo-obj-hold-hard     \tR: 727.0  \tS: 1.00\u001b[0m\n",
      "\u001b[1m\u001b[34mTask: myo-obj-hold-hard\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-obj-hold-hard-3.pt\u001b[0m\n",
      "\u001b[1m\u001b[33mEvaluating agent on myo-obj-hold-hard:\u001b[0m\n",
      "\u001b[33m  myo-obj-hold-hard     \tR: 483.2  \tS: 0.80\u001b[0m\n",
      "\u001b[1m\u001b[34mTask: myo-pen-twirl\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-pen-twirl-1.pt\u001b[0m\n",
      "\u001b[1m\u001b[33mEvaluating agent on myo-pen-twirl:\u001b[0m\n",
      "\u001b[33m  myo-pen-twirl         \tR: 5110.1  \tS: 1.00\u001b[0m\n",
      "\u001b[1m\u001b[34mTask: myo-pen-twirl\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-pen-twirl-2.pt\u001b[0m\n",
      "\u001b[1m\u001b[33mEvaluating agent on myo-pen-twirl:\u001b[0m\n",
      "\u001b[33m  myo-pen-twirl         \tR: 5202.5  \tS: 1.00\u001b[0m\n",
      "\u001b[1m\u001b[34mTask: myo-pen-twirl\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-pen-twirl-3.pt\u001b[0m\n",
      "\u001b[1m\u001b[33mEvaluating agent on myo-pen-twirl:\u001b[0m\n",
      "\u001b[33m  myo-pen-twirl         \tR: 5406.3  \tS: 1.00\u001b[0m\n",
      "\u001b[1m\u001b[34mTask: myo-pen-twirl-hard\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-pen-twirl-hard-1.pt\u001b[0m\n",
      "\u001b[1m\u001b[33mEvaluating agent on myo-pen-twirl-hard:\u001b[0m\n",
      "\u001b[33m  myo-pen-twirl-hard    \tR: 3354.8  \tS: 0.50\u001b[0m\n",
      "\u001b[1m\u001b[34mTask: myo-pen-twirl-hard\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-pen-twirl-hard-2.pt\u001b[0m\n",
      "\u001b[1m\u001b[33mEvaluating agent on myo-pen-twirl-hard:\u001b[0m\n",
      "\u001b[33m  myo-pen-twirl-hard    \tR: 2907.4  \tS: 0.40\u001b[0m\n",
      "\u001b[1m\u001b[34mTask: myo-pen-twirl-hard\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-pen-twirl-hard-3.pt\u001b[0m\n",
      "\u001b[1m\u001b[33mEvaluating agent on myo-pen-twirl-hard:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Nan, Inf or huge value in QACC at DOF 27. The simulation is unstable. Time = 0.8700.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[43m\u001b[30mSimulation couldn't be stepped as intended. Issuing a reset\u001b[0m\n",
      "\u001b[33m  myo-pen-twirl-hard    \tR: 3702.1  \tS: 0.50\u001b[0m\n",
      "\u001b[1m\u001b[34mTask: myo-pose\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-pose-1.pt\u001b[0m\n",
      "\u001b[1m\u001b[33mEvaluating agent on myo-pose:\u001b[0m\n",
      "\u001b[33m  myo-pose              \tR: 715.9  \tS: 1.00\u001b[0m\n",
      "\u001b[1m\u001b[34mTask: myo-pose\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-pose-2.pt\u001b[0m\n",
      "\u001b[1m\u001b[33mEvaluating agent on myo-pose:\u001b[0m\n",
      "\u001b[33m  myo-pose              \tR: 715.2  \tS: 1.00\u001b[0m\n",
      "\u001b[1m\u001b[34mTask: myo-pose\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-pose-3.pt\u001b[0m\n",
      "\u001b[1m\u001b[33mEvaluating agent on myo-pose:\u001b[0m\n",
      "\u001b[33m  myo-pose              \tR: 733.6  \tS: 1.00\u001b[0m\n",
      "\u001b[1m\u001b[34mTask: myo-pose-hard\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-pose-hard-1.pt\u001b[0m\n",
      "\u001b[1m\u001b[33mEvaluating agent on myo-pose-hard:\u001b[0m\n",
      "\u001b[33m  myo-pose-hard         \tR: 158.3  \tS: 0.10\u001b[0m\n",
      "\u001b[1m\u001b[34mTask: myo-pose-hard\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-pose-hard-2.pt\u001b[0m\n",
      "\u001b[1m\u001b[33mEvaluating agent on myo-pose-hard:\u001b[0m\n",
      "\u001b[33m  myo-pose-hard         \tR: 234.4  \tS: 0.10\u001b[0m\n",
      "\u001b[1m\u001b[34mTask: myo-pose-hard\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-pose-hard-3.pt\u001b[0m\n",
      "\u001b[1m\u001b[33mEvaluating agent on myo-pose-hard:\u001b[0m\n",
      "\u001b[33m  myo-pose-hard         \tR: 310.0  \tS: 0.40\u001b[0m\n",
      "\u001b[1m\u001b[34mTask: myo-reach\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-reach-1.pt\u001b[0m\n",
      "\u001b[1m\u001b[33mEvaluating agent on myo-reach:\u001b[0m\n",
      "\u001b[33m  myo-reach             \tR: 775.4  \tS: 1.00\u001b[0m\n",
      "\u001b[1m\u001b[34mTask: myo-reach\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-reach-2.pt\u001b[0m\n",
      "\u001b[1m\u001b[33mEvaluating agent on myo-reach:\u001b[0m\n",
      "\u001b[33m  myo-reach             \tR: 772.9  \tS: 1.00\u001b[0m\n",
      "\u001b[1m\u001b[34mTask: myo-reach\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-reach-3.pt\u001b[0m\n",
      "\u001b[1m\u001b[33mEvaluating agent on myo-reach:\u001b[0m\n",
      "\u001b[33m  myo-reach             \tR: 774.8  \tS: 1.00\u001b[0m\n",
      "\u001b[1m\u001b[34mTask: myo-reach-hard\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-reach-hard-1.pt\u001b[0m\n",
      "\u001b[1m\u001b[33mEvaluating agent on myo-reach-hard:\u001b[0m\n",
      "\u001b[33m  myo-reach-hard        \tR: 733.3  \tS: 1.00\u001b[0m\n",
      "\u001b[1m\u001b[34mTask: myo-reach-hard\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-reach-hard-2.pt\u001b[0m\n",
      "\u001b[1m\u001b[33mEvaluating agent on myo-reach-hard:\u001b[0m\n",
      "\u001b[33m  myo-reach-hard        \tR: 728.7  \tS: 0.90\u001b[0m\n",
      "\u001b[1m\u001b[34mTask: myo-reach-hard\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-reach-hard-3.pt\u001b[0m\n",
      "\u001b[1m\u001b[33mEvaluating agent on myo-reach-hard:\u001b[0m\n",
      "\u001b[33m  myo-reach-hard        \tR: 759.4  \tS: 1.00\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ckpt_scores = defaultdict(list)\n",
    "\n",
    "for ckpt in myo_ckpts: \n",
    "    with hydra.initialize(config_path='.'):\n",
    "        cfg = hydra.compose('config.yaml',\n",
    "                            return_hydra_config=True,\n",
    "                            overrides=[f'task={get_task(ckpt)}', \n",
    "                                       f'checkpoint={ckpt}'])\n",
    "        HydraConfig.instance().set_config(cfg)\n",
    "        cfg = parse_cfg(cfg)\n",
    "    ckpt_scores[get_task(ckpt)].append(evaluate(cfg))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mTask: myo-key-turn-hard\u001b[0m\n",
      "\u001b[1m\u001b[34mModel size: default\u001b[0m\n",
      "\u001b[1m\u001b[34mCheckpoint: /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-key-turn-hard-2.pt\u001b[0m\n",
      "\u001b[1m\u001b[33mEvaluating agent on myo-key-turn-hard:\u001b[0m\n",
      "\u001b[33m  myo-key-turn-hard     \tR: 1168.7  \tS: 0.10\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1168.6514, 0.1)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = myo_ckpts[4]\n",
    "with hydra.initialize(config_path='.'):\n",
    "    cfg = hydra.compose('config.yaml',\n",
    "                        return_hydra_config=True,\n",
    "                        overrides=[f'task={get_task(ckpt)}', \n",
    "                                    f'checkpoint={ckpt}',\n",
    "                                    'save_video=true'])\n",
    "    HydraConfig.instance().set_config(cfg)\n",
    "    cfg = parse_cfg(cfg)\n",
    "    env = make_env(cfg)\n",
    "    env._max_episode_steps\n",
    "\n",
    "evaluate(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/krishnans/ngc/tdmpc2/tdmpc2/logs/myo-key-turn-hard/1/default/videos')]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cfg.work_dir.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"/home/krishnans/ngc/tdmpc2/tdmpc2/logs/myo-key-turn-hard/1/default/videos/myo-key-turn-hard-1.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the video in the Jupyter notebook\n",
    "Video(str(list((cfg.work_dir / 'videos').iterdir())[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MJRenderer' object has no attribute '_scene_option'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, flag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([mujoco\u001b[38;5;241m.\u001b[39mmjtVisFlag(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m25\u001b[39m)]):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_scene_option\u001b[49m\u001b[38;5;241m.\u001b[39mflags[i]:\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28mprint\u001b[39m(flag)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MJRenderer' object has no attribute '_scene_option'"
     ]
    }
   ],
   "source": [
    "for i, flag in enumerate([mujoco.mjtVisFlag(i) for i in range(25)]):\n",
    "    if env.sim.renderer._scene_option.flags[i]:\n",
    "        print(flag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tdmpc2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

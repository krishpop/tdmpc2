{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import os\n",
    "os.environ['MUJOCO_GL'] = 'egl'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from hydra.core.hydra_config import HydraConfig\n",
    "from omegaconf import OmegaConf\n",
    "from huggingface_hub import HfFileSystem\n",
    "from huggingface_hub import hf_hub_download\n",
    "import torch.nn.functional as F\n",
    "import gym\n",
    "import h5py\n",
    "import imageio\n",
    "import numpy as np\n",
    "import torch\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "from termcolor import colored\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "\n",
    "from common.buffer import Buffer, RobomimicBuffer\n",
    "from common.parser import parse_cfg\n",
    "from common.seed import set_seed\n",
    "from envs import make_env\n",
    "from tdmpc2 import TDMPC2\n",
    "from collections import defaultdict\n",
    "from envs.wrappers.pixels import PixelWrapper\n",
    "\n",
    "from tensordict import TensorDict\n",
    "from mujoco import mjtVisFlag\n",
    "from IPython.display import Video\n",
    "from envs.myosuite import MYOSUITE_TASKS\n",
    "\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_td(obs, action, reward=None):\n",
    "    \"\"\"Creates a TensorDict for a new episode.\"\"\"\n",
    "    if isinstance(obs, dict):\n",
    "        obs = TensorDict(obs, batch_size=(), device='cpu')\n",
    "    else:\n",
    "        obs = obs.unsqueeze(0).cpu()\n",
    "    if reward is None:\n",
    "        reward = torch.tensor(float('nan'))\n",
    "    td = TensorDict(dict(\n",
    "        obs=obs.unsqueeze(0),\n",
    "        action=action.unsqueeze(0),\n",
    "        reward=torch.tensor(reward).unsqueeze(0),\n",
    "    ), batch_size=(1,))\n",
    "    return td\n",
    "\n",
    "\n",
    "def evaluate(cfg): \n",
    "    success_only = cfg.success_only\n",
    "    assert torch.cuda.is_available()\n",
    "    assert cfg.eval_episodes > 0, 'Must evaluate at least 1 episode.'\n",
    "    cfg = parse_cfg(cfg)\n",
    "    set_seed(cfg.seed)\n",
    "    print(colored(f'Task: {cfg.task}', 'blue', attrs=['bold']))\n",
    "    print(colored(f'Model size: {cfg.get(\"model_size\", \"default\")}', 'blue', attrs=['bold']))\n",
    "    print(colored(f'Checkpoint: {cfg.checkpoint}', 'blue', attrs=['bold']))\n",
    "    if not cfg.multitask and ('mt80' in cfg.checkpoint or 'mt30' in cfg.checkpoint):\n",
    "        print(colored('Warning: single-task evaluation of multi-task models is not currently supported.', 'red', attrs=['bold']))\n",
    "        print(colored('To evaluate a multi-task model, use task=mt80 or task=mt30.', 'red', attrs=['bold']))\n",
    "\n",
    "    # Make environment\n",
    "    env = make_env(cfg)\n",
    "    buffer = RobomimicBuffer(cfg)\n",
    "\n",
    "    # Load agent\n",
    "    agent = TDMPC2(cfg)\n",
    "    assert os.path.exists(cfg.checkpoint), f'Checkpoint {cfg.checkpoint} not found! Must be a valid filepath.'\n",
    "    agent.load(cfg.checkpoint)\n",
    "    \n",
    "    # Evaluate\n",
    "    if cfg.multitask:\n",
    "        print(colored(f'Evaluating agent on {len(cfg.tasks)} tasks:', 'yellow', attrs=['bold']))\n",
    "    else:\n",
    "        print(colored(f'Evaluating agent on {cfg.task}:', 'yellow', attrs=['bold']))\n",
    "    if cfg.save_video:\n",
    "        video_dir = os.path.join(cfg.work_dir, 'videos')\n",
    "        os.makedirs(video_dir, exist_ok=True)\n",
    "    scores = []\n",
    "    tasks = cfg.tasks if cfg.multitask else [cfg.task]\n",
    "    for task_idx, task in enumerate(tasks):\n",
    "        if not cfg.multitask:\n",
    "            task_idx = None\n",
    "        ep_rewards, ep_successes = [], []\n",
    "        for i in range(cfg.eval_episodes):\n",
    "            obs, done, ep_reward, t = env.reset(task_idx=task_idx), False, 0, 0\n",
    "            obs_dict = {\"vec_obs\": obs,  \"success\": False, \"fixed_camera\": env.render()}\n",
    "            _tds = [to_td(obs_dict, torch.zeros_like(env.rand_act()), ep_reward)]\n",
    "            if cfg.save_video:\n",
    "                frames = [env.render()]\n",
    "            while not done:\n",
    "                action = agent.act(obs, t0=t==0, task=task_idx)\n",
    "                obs, reward, done, info = env.step(action)\n",
    "                obs_dict = {\"vec_obs\": obs,  \"success\": np.array(info[\"solved\"], dtype=bool), \"fixed_camera\": env.render()}\n",
    "                _tds.append(to_td(obs_dict, action.flatten(), reward))\n",
    "                ep_reward += reward\n",
    "                t += 1\n",
    "                if cfg.save_video:\n",
    "                    frames.append(env.render())\n",
    "            \n",
    "            if success_only and info[\"success\"] or not success_only:\n",
    "                buffer.add(torch.cat(_tds))\n",
    "\n",
    "            ep_rewards.append(ep_reward)\n",
    "            ep_successes.append(info['success'])\n",
    "            if cfg.save_video:\n",
    "                imageio.mimsave(\n",
    "                    os.path.join(video_dir, f'{task}-{i}.mp4'), frames, fps=15)\n",
    "        buffer.save(cfg.hdf5_save_path)\n",
    "        ep_rewards = np.mean(ep_rewards)\n",
    "        ep_successes = np.mean(ep_successes)\n",
    "        if cfg.multitask:\n",
    "            scores.append(ep_successes*100 if task.startswith('mw-') else ep_rewards/10)\n",
    "        print(colored(f'  {task:<22}' \\\n",
    "            f'\\tR: {ep_rewards:.01f}  ' \\\n",
    "            f'\\tS: {ep_successes:.02f}', 'yellow'))\n",
    "    if cfg.multitask:\n",
    "        print(colored(f'Normalized score: {np.mean(scores):.02f}', 'yellow', attrs=['bold']))\n",
    "    return buffer\n",
    "\n",
    "def get_task(x):\n",
    "    x = x.split('/')[-1]\n",
    "    x = '-'.join(['myo'] + x.split('-')[2:-1]).rstrip('.pt')\n",
    "    return x\n",
    "\n",
    "\n",
    "def load_data(cfg):\n",
    "    # Load data\n",
    "    assert cfg.task in cfg.data_dir, \\\n",
    "        f'Expected data directory {cfg.data_dir} to contain {cfg.task}, ' \\\n",
    "        f'please double-check your config.'\n",
    "\n",
    "    # Create buffer for sampling\n",
    "    _cfg = deepcopy(cfg)\n",
    "    if _cfg.task.startswith(\"mt\"):\n",
    "        _cfg.episode_length = 101 if cfg.task == 'mt80' else 501\n",
    "        _cfg.buffer_size = 550_450_000 if cfg.task == 'mt80' else 345_690_000\n",
    "        buffer = Buffer(_cfg)\n",
    "        fp = Path(os.path.join(cfg.data_dir, '*.pt'))\n",
    "        fps = sorted(glob(str(fp)))\n",
    "    elif _cfg.task.startswith(\"myo\"):\n",
    "        _cfg.episode_length = 101\n",
    "        _cfg.buffer_size = 100_000\n",
    "        buffer = RobomimicBuffer(_cfg)\n",
    "        fp = Path(os.path.join(cfg.data_dir, '*.hdf5'))\n",
    "        fps = sorted(fp.rglob('*.hdf5'))\n",
    "    _cfg.steps = _cfg.buffer_size\n",
    "    \n",
    "    assert len(fps) > 0, f'No data found at {fp}'\n",
    "    print(f'Found {len(fps)} files in {fp}')\n",
    "\n",
    "    for fp in tqdm(fps, desc='Loading data'):\n",
    "        if _cfg.task.startswith(\"mt\"):\n",
    "            td = torch.load(fp)\n",
    "            assert td.shape[1] == _cfg.episode_length, \\\n",
    "                f'Expected episode length {td.shape[1]} to match config episode length {_cfg.episode_length}, ' \\\n",
    "                f'please double-check your config.'\n",
    "            for i in range(len(td)):\n",
    "                buffer.add(td[i])\n",
    "        else:\n",
    "            td = buffer.load_hdf5(fp)\n",
    "\n",
    "    assert buffer.num_eps == buffer.capacity, \\\n",
    "        f'Buffer has {buffer.num_eps} episodes, expected {buffer.capacity} episodes.'\n",
    "\n",
    "    return buffer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cfg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m buffer \u001b[38;5;241m=\u001b[39m evaluate(\u001b[43mcfg\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cfg' is not defined"
     ]
    }
   ],
   "source": [
    "buffer = evaluate(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"test.hdf5\", 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer._buffer.storage[buffer._buffer.storage['episode'] == 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer.save_hdf5('test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id = \"nicklashansen/tdmpc2\"\n",
    "subfolder = \"myosuite\"\n",
    "\n",
    "# List of checkpoint filenames to download\n",
    "fs = HfFileSystem()\n",
    "\n",
    "checkpoint_files = map(lambda x: x.split('/')[-1], fs.glob(f\"{repo_id}/myosuite/*.pt\"))\n",
    "\n",
    "myo_ckpts = []\n",
    "# Download each checkpoint\n",
    "for file_name in checkpoint_files:\n",
    "    file_path = hf_hub_download(repo_id, filename=file_name, subfolder=subfolder)\n",
    "    print(f\"Downloaded {file_name} to {file_path}\")\n",
    "    myo_ckpts.append(file_path)\n",
    "\n",
    "subfolder_path = os.path.split(myo_ckpts[0])[0]\n",
    "\n",
    "# subfolder = \"dmcontrol\"\n",
    "\n",
    "# checkpoint_files = ['dog-run-1.pt']\n",
    "\n",
    "# dmcontrol_ckpts = []\n",
    "\n",
    "# for file_name in checkpoint_files:\n",
    "#     file_path = hf_hub_download(repo_id, filename=file_name, subfolder=subfolder)\n",
    "#     print(f\"Downloaded {file_name} to {file_path}\")\n",
    "#     dmcontrol_ckpts.append(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'myo_ckpts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m ckpt_scores \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ckpt \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmyo_ckpts\u001b[49m: \n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hydra\u001b[38;5;241m.\u001b[39minitialize(config_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      5\u001b[0m         cfg \u001b[38;5;241m=\u001b[39m hydra\u001b[38;5;241m.\u001b[39mcompose(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m                             return_hydra_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m                             overrides\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mget_task(ckpt)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      8\u001b[0m                                        \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mckpt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'myo_ckpts' is not defined"
     ]
    }
   ],
   "source": [
    "ckpt_scores = defaultdict(list)\n",
    "\n",
    "for ckpt in myo_ckpts: \n",
    "    with hydra.initialize(config_path='.'):\n",
    "        cfg = hydra.compose('config.yaml',\n",
    "                            return_hydra_config=True,\n",
    "                            overrides=[f'task={get_task(ckpt)}', \n",
    "                                       f'checkpoint={ckpt}'])\n",
    "        HydraConfig.instance().set_config(cfg)\n",
    "        cfg = parse_cfg(cfg)\n",
    "    ckpt_scores[get_task(ckpt)].append(evaluate(cfg))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyoSuite:> Registering Myo Envs\n",
      "\u001b[36m    MyoSuite: A contact-rich simulation suite for musculoskeletal motor control\n",
      "        Vittorio Caggiano, Huawei Wang, Guillaume Durandau, Massimo Sartori, Vikash Kumar\n",
      "        L4DC-2019 | https://sites.google.com/view/myosuite\n",
      "    \u001b[0m\n",
      "myo-pose-hard ep len 100\n"
     ]
    }
   ],
   "source": [
    "# ckpt = myo_ckpts[0]\n",
    "ckpt = \" /home/krishnans/.cache/huggingface/hub/models--nicklashansen--tdmpc2/snapshots/8fb2a82efb3bae96941da440128fe1332e4394fd/myosuite/myo-hand-pose-hard-1.pt\"\n",
    "with hydra.initialize(config_path='.'):\n",
    "    cfg = hydra.compose('config.yaml',\n",
    "                        return_hydra_config=True,\n",
    "                        overrides=[f'task={get_task(ckpt)}', \n",
    "                                    f'checkpoint={ckpt}',\n",
    "                                    f'buffer_size=1_000_000',\n",
    "                                    'save_video=true'])\n",
    "    HydraConfig.instance().set_config(cfg)\n",
    "    cfg = parse_cfg(cfg)\n",
    "    env = make_env(cfg)\n",
    "    print(f\"{cfg.task} ep len\", env.env._max_episode_steps)\n",
    "\n",
    "# evaluate(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffer capacity: 100,000\n",
      "Storage required: 4.98 GB\n",
      "Using CUDA memory for storage.\n"
     ]
    }
   ],
   "source": [
    "env = make_env(cfg)\n",
    "buffer = RobomimicBuffer(cfg)\n",
    "cfg.buffer_size = 100_000\n",
    "data_path = \"/home/krishnans/ngc/tdmpc2/datasets/myo-pose-hard/myo-pose-hard_500.hdf5\"\n",
    "# buffer.load_hdf5(data_path)\n",
    "\n",
    "cfg.buffer_size = 100_000\n",
    "transform = transforms.Compose([\n",
    "                        transforms.ToPILImage(),\n",
    "                        transforms.Resize((64, 64)),\n",
    "                        transforms.ToTensor()\n",
    "                    ])\n",
    "\n",
    "# Load agent\n",
    "agent = TDMPC2(cfg)\n",
    "assert os.path.exists(cfg.checkpoint), f'Checkpoint {cfg.checkpoint} not found! Must be a valid filepath.'\n",
    "agent.load(cfg.checkpoint)\n",
    "\n",
    "\n",
    "with h5py.File(data_path, \"r\") as f:\n",
    "    for episode_id in range(len(f[\"data\"])):\n",
    "        episode_group = f[f\"data/demo_{episode_id}\"]\n",
    "        num_samples = episode_group.attrs[\"num_samples\"]\n",
    "        episode_td = {}\n",
    "        episode_transitions = []\n",
    "        for key in episode_group.keys():\n",
    "            if isinstance(episode_group[key], h5py.Group):\n",
    "                sub_dict = {}\n",
    "                for sub_key in episode_group[key].keys():\n",
    "                    if sub_key == 'fixed_camera':\n",
    "                        sub_dict[sub_key] = torch.stack([transform(img) for img in episode_group[key][sub_key][:]])\n",
    "                    else:\n",
    "                        sub_dict[sub_key] = torch.tensor(episode_group[key][sub_key][:])\n",
    "                episode_td[key] = TensorDict(sub_dict, batch_size=(num_samples,))\n",
    "            else:\n",
    "                episode_td[key] = torch.tensor(episode_group[key][:])\n",
    "        episode_td = TensorDict(episode_td, batch_size=(num_samples,))\n",
    "        buffer.add(episode_td)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffer capacity: 50,000\n",
      "Storage required: 22.13 GB\n",
      "Using CPU memory for storage.\n"
     ]
    }
   ],
   "source": [
    "data_dir = list(Path(\"/home/krishnans/ngc/tdmpc2/datasets\").rglob(\"*.hdf5\"))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                        transforms.ToPILImage(),\n",
    "                        transforms.Resize((64, 64)),\n",
    "                        transforms.ToTensor()\n",
    "                    ])\n",
    "\n",
    "max_vec_obs_dim = 0\n",
    "max_action_dim = 0\n",
    "for fp in data_dir:\n",
    "    with h5py.File(str(fp), 'r') as f:\n",
    "        episode_id = 0\n",
    "        if \"vec_obs\" in f[f\"data/demo_{episode_id}\"]:\n",
    "            vec_obs_group = f[f\"data/demo_{episode_id}/vec_obs\"]\n",
    "            for vec_obs_key in vec_obs_group.keys():\n",
    "                vec_obs_shape = vec_obs_group[vec_obs_key].shape\n",
    "                if len(vec_obs_shape) > 1 and vec_obs_shape[1] > max_vec_obs_dim:\n",
    "                    max_vec_obs_dim = vec_obs_shape[1]\n",
    "        if \"action\" in f[f\"data/demo_{episode_id}\"]:\n",
    "            action_shape= f[f\"data/demo_{episode_id}/action\"].shape\n",
    "            if len(action_shape) > 1 and action_shape[1] > max_action_dim:\n",
    "                max_action_dim = action_shape[1]\n",
    "\n",
    "pad_vec_obs = transforms.Lambda(lambda x: F.pad(input=x, pad=(0, max_vec_obs_dim - x.shape[1]), mode='constant', value=0))\n",
    "pad_action = transforms.Lambda(lambda x: F.pad(input=x, pad=(0, max_action_dim - x.shape[1]), mode='constant', value=0))\n",
    "\n",
    "cfg.buffer_size = 90_000\n",
    "buffer = RobomimicBuffer(cfg)\n",
    "for fp in data_dir:\n",
    "    f = h5py.File(str(fp), 'r')\n",
    "    for episode_id in range(len(f[\"data\"])):\n",
    "        episode_group = f[f\"data/demo_{episode_id}\"]\n",
    "        num_samples = episode_group.attrs[\"num_samples\"]\n",
    "        episode_td = {}\n",
    "        episode_transitions = []\n",
    "        for key in episode_group.keys():\n",
    "            if isinstance(episode_group[key], h5py.Group):\n",
    "                sub_dict = {}\n",
    "                for sub_key in episode_group[key].keys():\n",
    "                    if sub_key == 'fixed_camera':\n",
    "                        sub_value = torch.stack([transform(img) for img in episode_group[key][sub_key][:]])\n",
    "                    if sub_key == 'vec_obs':\n",
    "                        sub_value = pad_vec_obs(torch.tensor(episode_group[key][sub_key][:]))\n",
    "                    else:\n",
    "                        sub_value = torch.tensor(episode_group[key][sub_key][:])\n",
    "                    sub_dict[sub_key] = sub_value\n",
    "                episode_td[key] = TensorDict(sub_dict, batch_size=(num_samples,))\n",
    "            else:\n",
    "                if key == 'action':\n",
    "                    episode_td[key] = pad_action(torch.tensor(episode_group[key][:]))\n",
    "                else:\n",
    "                    episode_td[key] = torch.tensor(episode_group[key][:])\n",
    "        episode_transitions = TensorDict(episode_td, batch_size=(num_samples,))\n",
    "        buffer.add(episode_transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.data_dir = \"/home/krishnans/ngc/tdmpc2/datasets\"\n",
    "load_data(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer.load_hdf5(\"/home/krishnans/ngc/tdmpc2/datasets/myo-pose-hard_500.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer.load_hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(cfg.work_dir.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the video in the Jupyter notebook\n",
    "Video(str(list((cfg.work_dir / 'videos').iterdir())[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, flag in enumerate([mujoco.mjtVisFlag(i) for i in range(25)]):\n",
    "    if env.sim.renderer._scene_option.flags[i]:\n",
    "        print(flag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tdmpc2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

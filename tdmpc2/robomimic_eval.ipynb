{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishnans/miniconda3/envs/robomimic/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/krishnans/miniconda3/envs/robomimic/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"MUJOCO_GL\"] = \"egl\"\n",
    "from common.parser import parse_cfg\n",
    "from common.seed import set_seed\n",
    "from envs import make_env\n",
    "from envs.myosuite import MYOSUITE_TASKS\n",
    "from tdmpc2 import TDMPC2\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import robomimic\n",
    "import robomimic.utils.file_utils as FileUtils\n",
    "import robomimic.utils.torch_utils as TorchUtils\n",
    "import robomimic.utils.tensor_utils as TensorUtils\n",
    "import robomimic.utils.obs_utils as ObsUtils\n",
    "import robomimic.utils.env_utils as EnvUtils\n",
    "from robomimic.envs.env_base import EnvBase\n",
    "from robomimic.algo import RolloutPolicy\n",
    "\n",
    "import h5py\n",
    "import json\n",
    "import hydra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['myo-reach',\n",
       " 'myo-reach-hard',\n",
       " 'myo-pose',\n",
       " 'myo-pose-hard',\n",
       " 'myo-obj-hold',\n",
       " 'myo-obj-hold-hard',\n",
       " 'myo-key-turn',\n",
       " 'myo-key-turn-hard',\n",
       " 'myo-pen-twirl',\n",
       " 'myo-pen-twirl-hard']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(MYOSUITE_TASKS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing env args to dataset: /home/krishnans/multi_task_experts/datasets/myo10/myo-reach/myo-reach_515.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_689835/3445706401.py:10: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with hydra.initialize():\n",
      "/tmp/ipykernel_689835/3445706401.py:10: UserWarning: config_path is not specified in hydra.initialize().\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/changes_to_hydra_main_config_path for more information.\n",
      "  with hydra.initialize():\n"
     ]
    }
   ],
   "source": [
    "ckpt_dir = Path(\"/home/krishnans/ngc/tdmpc2/ckpts/myosuite\")\n",
    "data_dir = Path(\"/home/krishnans/multi_task_experts/datasets/myo10/\")\n",
    "for task in list(MYOSUITE_TASKS.keys()):\n",
    "    task_name = \"-\".join([task.split(\"-\")[0], \"hand\"] + task.split(\"-\")[1:])\n",
    "    ckpt = ckpt_dir / f\"{task_name}-1.pt\" \n",
    "    overrides = [\"hydra/launcher=basic\"]\n",
    "    overrides.append(f\"task={task}\")\n",
    "    overrides.append(f\"checkpoint={str(ckpt.resolve())}\")\n",
    "\n",
    "    with hydra.initialize():\n",
    "        cfg = hydra.compose(\"config.yaml\", overrides=overrides)\n",
    "\n",
    "    dataset_path = list(data_dir.rglob(f\"{task}_*.hdf5\"))[0]\n",
    "    assert dataset_path.exists()\n",
    "    with h5py.File(str(dataset_path), \"a\") as f:\n",
    "        print(f\"writing env args to dataset: {str(dataset_path)}\") \n",
    "        env_kwargs = OmegaConf.to_container(cfg, resolve=True)\n",
    "        env_kwargs[\"pad_to_shape\"] = (115,)\n",
    "        env_args = {\"env_name\": MYOSUITE_TASKS[task], \"type\": 4, \"env_kwargs\": env_kwargs}\n",
    "        break\n",
    "        f[\"data\"].attrs[\"env_args\"] = json.dumps(env_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: could not load d4rl environments!\n",
      "MyoSuite:> Registering Myo Envs\n",
      "\u001b[36m    MyoSuite: A contact-rich simulation suite for musculoskeletal motor control\n",
      "        Vittorio Caggiano, Huawei Wang, Guillaume Durandau, Massimo Sartori, Vikash Kumar\n",
      "        L4DC-2019 | https://sites.google.com/view/myosuite\n",
      "    \u001b[0m\n",
      "Created environment with name myoHandReachFixed-v0\n",
      "Action size is 39\n",
      "\u001b[33mROBOMIMIC WARNING(\n",
      "    No environment version found in dataset!\n",
      "    Cannot verify if dataset and installed environment versions match\n",
      ")\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = EnvUtils.create_env_from_metadata(env_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Loaded Config =============\n",
      "{\n",
      "    \"algo_name\": \"act\",\n",
      "    \"experiment\": {\n",
      "        \"name\": \"test-myo-act\",\n",
      "        \"validate\": false,\n",
      "        \"logging\": {\n",
      "            \"terminal_output_to_txt\": true,\n",
      "            \"log_tb\": true,\n",
      "            \"log_wandb\": false,\n",
      "            \"wandb_proj_name\": \"debug\"\n",
      "        },\n",
      "        \"mse\": {\n",
      "            \"enabled\": false,\n",
      "            \"every_n_epochs\": 50,\n",
      "            \"on_save_ckpt\": true,\n",
      "            \"num_samples\": 20,\n",
      "            \"visualize\": true\n",
      "        },\n",
      "        \"save\": {\n",
      "            \"enabled\": true,\n",
      "            \"every_n_seconds\": null,\n",
      "            \"every_n_epochs\": 40,\n",
      "            \"epochs\": [],\n",
      "            \"on_best_validation\": false,\n",
      "            \"on_best_rollout_return\": false,\n",
      "            \"on_best_rollout_success_rate\": true\n",
      "        },\n",
      "        \"epoch_every_n_steps\": 500,\n",
      "        \"validation_epoch_every_n_steps\": 10,\n",
      "        \"env\": null,\n",
      "        \"additional_envs\": null,\n",
      "        \"render\": false,\n",
      "        \"render_video\": true,\n",
      "        \"keep_all_videos\": false,\n",
      "        \"video_skip\": 5,\n",
      "        \"rollout\": {\n",
      "            \"enabled\": false,\n",
      "            \"n\": 50,\n",
      "            \"horizon\": 400,\n",
      "            \"rate\": 40,\n",
      "            \"warmstart\": 0,\n",
      "            \"terminate_on_success\": true,\n",
      "            \"batched\": false,\n",
      "            \"num_batch_envs\": 5\n",
      "        },\n",
      "        \"env_meta_update_dict\": {},\n",
      "        \"ckpt_path\": null\n",
      "    },\n",
      "    \"train\": {\n",
      "        \"data\": [\n",
      "            {\n",
      "                \"path\": \"/home/krishnans/multi_task_experts/collect_myosuite/outputs/2024-05-28/10-29-43/myo-reach-hard_150.hdf5\",\n",
      "                \"weight\": 0.34\n",
      "            },\n",
      "            {\n",
      "                \"path\": \"/home/krishnans/multi_task_experts/collect_myosuite/outputs/2024-05-28/10-30-46/myo-pen-twirl-hard_150.hdf5\",\n",
      "                \"weight\": 0.33\n",
      "            },\n",
      "            {\n",
      "                \"path\": \"/home/krishnans/multi_task_experts/collect_myosuite/outputs/2024-05-28/10-37-18/myo-obj-hold-hard_150.hdf5\",\n",
      "                \"weight\": 0.33\n",
      "            }\n",
      "        ],\n",
      "        \"output_dir\": \"../act_myo_trained_models\",\n",
      "        \"num_data_workers\": 0,\n",
      "        \"hdf5_cache_mode\": \"all\",\n",
      "        \"hdf5_use_swmr\": true,\n",
      "        \"hdf5_load_next_obs\": false,\n",
      "        \"hdf5_normalize_obs\": false,\n",
      "        \"hdf5_filter_key\": null,\n",
      "        \"hdf5_validation_filter_key\": null,\n",
      "        \"seq_length\": 10,\n",
      "        \"pad_seq_length\": true,\n",
      "        \"frame_stack\": 1,\n",
      "        \"pad_frame_stack\": true,\n",
      "        \"dataset_keys\": [\n",
      "            \"action\"\n",
      "        ],\n",
      "        \"action_keys\": [\n",
      "            \"action\"\n",
      "        ],\n",
      "        \"action_config\": {\n",
      "            \"action\": {\n",
      "                \"type\": \"continuous\",\n",
      "                \"dim\": 39,\n",
      "                \"normalization\": \"gaussian\"\n",
      "            }\n",
      "        },\n",
      "        \"goal_mode\": null,\n",
      "        \"cuda\": true,\n",
      "        \"batch_size\": 100,\n",
      "        \"num_epochs\": 10000,\n",
      "        \"seed\": 1,\n",
      "        \"max_grad_norm\": null,\n",
      "        \"data_format\": \"robomimic\",\n",
      "        \"load_env_meta\": false,\n",
      "        \"shuffled_obs_key_groups\": null,\n",
      "        \"meta_ds_class\": \"PadMetaDataset\",\n",
      "        \"meta_ds_kwargs\": {\n",
      "            \"pad_to_shape\": {\n",
      "                \"vec_obs\": [\n",
      "                    115\n",
      "                ]\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"algo\": {\n",
      "        \"optim_params\": {\n",
      "            \"policy\": {\n",
      "                \"optimizer_type\": \"adamw\",\n",
      "                \"learning_rate\": {\n",
      "                    \"initial\": 5e-05,\n",
      "                    \"decay_factor\": 1,\n",
      "                    \"epoch_schedule\": [\n",
      "                        100\n",
      "                    ],\n",
      "                    \"scheduler_type\": \"linear\"\n",
      "                },\n",
      "                \"regularization\": {\n",
      "                    \"L2\": 0.0001\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"loss\": {\n",
      "            \"l2_weight\": 0.0,\n",
      "            \"l1_weight\": 1.0,\n",
      "            \"vq_weight\": 1.0,\n",
      "            \"vq_l1_weight\": 1.0,\n",
      "            \"vq_ce_weight\": 0.0,\n",
      "            \"cos_weight\": 0.0,\n",
      "            \"kl_weight\": 10\n",
      "        },\n",
      "        \"act\": {\n",
      "            \"hidden_dim\": 512,\n",
      "            \"dim_feedforward\": 3200,\n",
      "            \"backbone\": \"resnet18\",\n",
      "            \"enc_layers\": 4,\n",
      "            \"dec_layers\": 7,\n",
      "            \"nheads\": 8,\n",
      "            \"latent_dim\": 32,\n",
      "            \"vq\": true,\n",
      "            \"vq_dim\": 64,\n",
      "            \"vq_class\": 512,\n",
      "            \"vq_weight\": 0.25\n",
      "        }\n",
      "    },\n",
      "    \"observation\": {\n",
      "        \"modalities\": {\n",
      "            \"obs\": {\n",
      "                \"low_dim\": [\n",
      "                    \"vec_obs\"\n",
      "                ],\n",
      "                \"rgb\": [\n",
      "                    \"fixed_camera\"\n",
      "                ],\n",
      "                \"depth\": [],\n",
      "                \"scan\": []\n",
      "            },\n",
      "            \"goal\": {\n",
      "                \"low_dim\": [],\n",
      "                \"rgb\": [],\n",
      "                \"depth\": [],\n",
      "                \"scan\": []\n",
      "            }\n",
      "        },\n",
      "        \"encoder\": {\n",
      "            \"low_dim\": {\n",
      "                \"core_class\": null,\n",
      "                \"core_kwargs\": {},\n",
      "                \"obs_randomizer_class\": null,\n",
      "                \"obs_randomizer_kwargs\": {}\n",
      "            },\n",
      "            \"rgb\": {\n",
      "                \"core_class\": \"VisualCore\",\n",
      "                \"core_kwargs\": {\n",
      "                    \"feature_dimension\": 64,\n",
      "                    \"backbone_class\": \"ResNet18Conv\",\n",
      "                    \"backbone_kwargs\": {\n",
      "                        \"pretrained\": false,\n",
      "                        \"input_coord_conv\": false\n",
      "                    },\n",
      "                    \"pool_class\": \"SpatialSoftmax\",\n",
      "                    \"pool_kwargs\": {\n",
      "                        \"num_kp\": 32,\n",
      "                        \"learnable_temperature\": false,\n",
      "                        \"temperature\": 1.0,\n",
      "                        \"noise_std\": 0.0\n",
      "                    }\n",
      "                },\n",
      "                \"obs_randomizer_class\": \"CropRandomizer\",\n",
      "                \"obs_randomizer_kwargs\": {\n",
      "                    \"crop_height\": 200,\n",
      "                    \"crop_width\": 200,\n",
      "                    \"num_crops\": 1,\n",
      "                    \"pos_enc\": false\n",
      "                }\n",
      "            },\n",
      "            \"depth\": {\n",
      "                \"core_class\": \"VisualCore\",\n",
      "                \"core_kwargs\": {},\n",
      "                \"obs_randomizer_class\": null,\n",
      "                \"obs_randomizer_kwargs\": {}\n",
      "            },\n",
      "            \"scan\": {\n",
      "                \"core_class\": \"ScanCore\",\n",
      "                \"core_kwargs\": {},\n",
      "                \"obs_randomizer_class\": null,\n",
      "                \"obs_randomizer_kwargs\": {}\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"meta\": {\n",
      "        \"hp_base_config_file\": null,\n",
      "        \"hp_keys\": [],\n",
      "        \"hp_values\": []\n",
      "    }\n",
      "}\n",
      "\n",
      "============= Initialized Observation Utils with Obs Spec =============\n",
      "\n",
      "using obs modality: low_dim with keys: ['vec_obs']\n",
      "using obs modality: rgb with keys: ['fixed_camera']\n",
      "using obs modality: depth with keys: []\n",
      "using obs modality: scan with keys: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishnans/miniconda3/envs/robomimic/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/krishnans/miniconda3/envs/robomimic/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use VQ: True, 512, 64\n",
      "number of parameters: 117.54M\n",
      "============= Loaded Policy =============\n",
      "ACT (\n",
      "  ModuleDict(\n",
      "    (policy): DETRVAE(\n",
      "      (transformer): Transformer(\n",
      "        (encoder): TransformerEncoder(\n",
      "          (layers): ModuleList(\n",
      "            (0-3): 4 x TransformerEncoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=3200, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=3200, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (decoder): TransformerDecoder(\n",
      "          (layers): ModuleList(\n",
      "            (0-6): 7 x TransformerDecoderLayer(\n",
      "              (self_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (multihead_attn): MultiheadAttention(\n",
      "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "              )\n",
      "              (linear1): Linear(in_features=512, out_features=3200, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (linear2): Linear(in_features=3200, out_features=512, bias=True)\n",
      "              (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout1): Dropout(p=0.1, inplace=False)\n",
      "              (dropout2): Dropout(p=0.1, inplace=False)\n",
      "              (dropout3): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (encoder): TransformerEncoder(\n",
      "        (layers): ModuleList(\n",
      "          (0-3): 4 x TransformerEncoderLayer(\n",
      "            (self_attn): MultiheadAttention(\n",
      "              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "            )\n",
      "            (linear1): Linear(in_features=512, out_features=3200, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (linear2): Linear(in_features=3200, out_features=512, bias=True)\n",
      "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout1): Dropout(p=0.1, inplace=False)\n",
      "            (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (action_head): Linear(in_features=512, out_features=39, bias=True)\n",
      "      (is_pad_head): Linear(in_features=512, out_features=1, bias=True)\n",
      "      (query_embed): Embedding(10, 512)\n",
      "      (input_proj): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (backbones): ModuleList(\n",
      "        (0): Joiner(\n",
      "          (0): Backbone(\n",
      "            (body): IntermediateLayerGetter(\n",
      "              (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "              (bn1): FrozenBatchNorm2d()\n",
      "              (relu): ReLU(inplace=True)\n",
      "              (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "              (layer1): Sequential(\n",
      "                (0): BasicBlock(\n",
      "                  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (bn1): FrozenBatchNorm2d()\n",
      "                  (relu): ReLU(inplace=True)\n",
      "                  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (bn2): FrozenBatchNorm2d()\n",
      "                )\n",
      "                (1): BasicBlock(\n",
      "                  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (bn1): FrozenBatchNorm2d()\n",
      "                  (relu): ReLU(inplace=True)\n",
      "                  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (bn2): FrozenBatchNorm2d()\n",
      "                )\n",
      "              )\n",
      "              (layer2): Sequential(\n",
      "                (0): BasicBlock(\n",
      "                  (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                  (bn1): FrozenBatchNorm2d()\n",
      "                  (relu): ReLU(inplace=True)\n",
      "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (bn2): FrozenBatchNorm2d()\n",
      "                  (downsample): Sequential(\n",
      "                    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                    (1): FrozenBatchNorm2d()\n",
      "                  )\n",
      "                )\n",
      "                (1): BasicBlock(\n",
      "                  (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (bn1): FrozenBatchNorm2d()\n",
      "                  (relu): ReLU(inplace=True)\n",
      "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (bn2): FrozenBatchNorm2d()\n",
      "                )\n",
      "              )\n",
      "              (layer3): Sequential(\n",
      "                (0): BasicBlock(\n",
      "                  (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                  (bn1): FrozenBatchNorm2d()\n",
      "                  (relu): ReLU(inplace=True)\n",
      "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (bn2): FrozenBatchNorm2d()\n",
      "                  (downsample): Sequential(\n",
      "                    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                    (1): FrozenBatchNorm2d()\n",
      "                  )\n",
      "                )\n",
      "                (1): BasicBlock(\n",
      "                  (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (bn1): FrozenBatchNorm2d()\n",
      "                  (relu): ReLU(inplace=True)\n",
      "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (bn2): FrozenBatchNorm2d()\n",
      "                )\n",
      "              )\n",
      "              (layer4): Sequential(\n",
      "                (0): BasicBlock(\n",
      "                  (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                  (bn1): FrozenBatchNorm2d()\n",
      "                  (relu): ReLU(inplace=True)\n",
      "                  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (bn2): FrozenBatchNorm2d()\n",
      "                  (downsample): Sequential(\n",
      "                    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                    (1): FrozenBatchNorm2d()\n",
      "                  )\n",
      "                )\n",
      "                (1): BasicBlock(\n",
      "                  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (bn1): FrozenBatchNorm2d()\n",
      "                  (relu): ReLU(inplace=True)\n",
      "                  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (bn2): FrozenBatchNorm2d()\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): PositionEmbeddingSine()\n",
      "        )\n",
      "      )\n",
      "      (input_proj_robot_state): Linear(in_features=115, out_features=512, bias=True)\n",
      "      (cls_embed): Embedding(1, 512)\n",
      "      (encoder_action_proj): Linear(in_features=39, out_features=512, bias=True)\n",
      "      (encoder_joint_proj): Linear(in_features=115, out_features=512, bias=True)\n",
      "      (latent_proj): Linear(in_features=512, out_features=32768, bias=True)\n",
      "      (latent_out_proj): Linear(in_features=32768, out_features=512, bias=True)\n",
      "      (additional_pos_embed): Embedding(2, 512)\n",
      "    )\n",
      "    (latent_model): Latent_Model_Transformer(\n",
      "      (input_layer): Linear(in_features=64, out_features=256, bias=True)\n",
      "      (weight_pos_embed): Embedding(512, 256)\n",
      "      (attention_blocks): Sequential(\n",
      "        (0): Dropout(p=0.1, inplace=False)\n",
      "        (1): Causal_Transformer_Block(\n",
      "          (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): Causal_Transformer_Block(\n",
      "          (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): Causal_Transformer_Block(\n",
      "          (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (1): GELU(approximate='none')\n",
      "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (output_layer): Linear(in_features=256, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = \"/home/krishnans/ngc/robomimic/act_myo10/models/model_epoch_280.pth\"\n",
    "\n",
    "policy, ckpt_dict = FileUtils.policy_from_checkpoint(\n",
    "    ckpt_path=ckpt_path, \n",
    "    device='cuda:0', \n",
    "    verbose=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

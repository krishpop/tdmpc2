{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mROBOMIMIC WARNING(\n",
      "    No private macro file found!\n",
      "    It is recommended to use a private macro file\n",
      "    To setup, run: python /home/bsud/multi_task_experts/robomimic/robomimic/scripts/setup_macros.py\n",
      ")\u001b[0m\n",
      "MyoSuite:> Registering Myo Envs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"MUJOCO_GL\"] = \"egl\"\n",
    "os.environ[\"TDMPC_PATH\"] = \"/home/bsud/multi_task_experts/collect_myosuite/tdmpc2\"\n",
    "from common.parser import parse_cfg\n",
    "from common.seed import set_seed\n",
    "from envs import make_env\n",
    "from envs.myosuite import MYOSUITE_TASKS\n",
    "from tdmpc2 import TDMPC2\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import robomimic\n",
    "import robomimic.utils.file_utils as FileUtils\n",
    "import robomimic.utils.torch_utils as TorchUtils\n",
    "import robomimic.utils.tensor_utils as TensorUtils\n",
    "import robomimic.utils.obs_utils as ObsUtils\n",
    "import robomimic.utils.env_utils as EnvUtils\n",
    "from robomimic.envs.env_base import EnvBase\n",
    "from robomimic.algo import RolloutPolicy\n",
    "\n",
    "import h5py\n",
    "import json\n",
    "import hydra\n",
    "import numpy as np\n",
    "import myosuite\n",
    "import torch\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['myo-reach',\n",
       " 'myo-reach-hard',\n",
       " 'myo-pose',\n",
       " 'myo-pose-hard',\n",
       " 'myo-obj-hold',\n",
       " 'myo-obj-hold-hard',\n",
       " 'myo-key-turn',\n",
       " 'myo-key-turn-hard',\n",
       " 'myo-pen-twirl',\n",
       " 'myo-pen-twirl-hard']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_keys = list(MYOSUITE_TASKS.keys())\n",
    "task_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add env args to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_96877/3813637261.py:10: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with hydra.initialize():\n",
      "/var/tmp/ipykernel_96877/3813637261.py:10: UserWarning: config_path is not specified in hydra.initialize().\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/changes_to_hydra_main_config_path for more information.\n",
      "  with hydra.initialize():\n",
      "/var/tmp/ipykernel_96877/3813637261.py:10: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with hydra.initialize():\n",
      "/var/tmp/ipykernel_96877/3813637261.py:10: UserWarning: config_path is not specified in hydra.initialize().\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/changes_to_hydra_main_config_path for more information.\n",
      "  with hydra.initialize():\n"
     ]
    }
   ],
   "source": [
    "ckpt_dir = Path(\"/home/bsud/multi_task_experts/robomimic/bc_trained_models/test\")\n",
    "data_dir = Path(\"/home/bsud/distill-act-datasets/\")\n",
    "for task in list(MYOSUITE_TASKS.keys()):\n",
    "    task_name = \"-\".join([task.split(\"-\")[0], \"hand\"] + task.split(\"-\")[1:])\n",
    "    ckpt = ckpt_dir / f\"{task_name}-1.pt\" \n",
    "    overrides = [\"hydra/launcher=basic\"]\n",
    "    overrides.append(f\"task={task}\")\n",
    "    overrides.append(f\"checkpoint={str(ckpt.resolve())}\")\n",
    "\n",
    "    with hydra.initialize():\n",
    "        cfg = hydra.compose(\"config.yaml\", overrides=overrides)\n",
    "\n",
    "    dataset_path = list(data_dir.rglob(f\"{task}_*.hdf5\"))[0]\n",
    "    assert dataset_path.exists()\n",
    "    with h5py.File(str(dataset_path), \"a\") as f:\n",
    "        env_kwargs = OmegaConf.to_container(cfg, resolve=True)\n",
    "        env_kwargs[\"pad_to_shape\"] = (115,)\n",
    "        env_args = {\"env_name\": MYOSUITE_TASKS[task], \"type\": 4, \"env_kwargs\": env_kwargs}\n",
    "        f[\"data\"].attrs[\"env_args\"] = json.dumps(env_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attrs  {\"env_name\": \"myoHandKeyTurnFixed-v0\", \"type\": 4, \"env_kwargs\": {\"task\": \"myo-key-turn\", \"obs\": \"state\", \"num_frames\": 3, \"render_size\": 64, \"checkpoint\": \"/home/bsud/multi_task_experts/robomimic/bc_trained_models/myo-hand-key-turn-1.pt\", \"eval_episodes\": 10, \"eval_freq\": 50000, \"use_buffer\": true, \"hdf5_path\": null, \"num_episode_limit\": 500, \"steps\": 1000000, \"batch_size\": 256, \"reward_coef\": 0.1, \"value_coef\": 0.1, \"consistency_coef\": 20, \"rho\": 0.5, \"lr\": 0.0003, \"enc_lr_scale\": 0.3, \"grad_clip_norm\": 20, \"tau\": 0.01, \"discount_denom\": 5, \"discount_min\": 0.95, \"discount_max\": 0.995, \"buffer_size\": 1000000, \"exp_name\": \"default\", \"data_dir\": \"???\", \"mpc\": true, \"iterations\": 6, \"num_samples\": 512, \"num_elites\": 64, \"num_pi_trajs\": 24, \"horizon\": 3, \"min_std\": 0.05, \"max_std\": 2, \"temperature\": 0.5, \"log_std_min\": -10, \"log_std_max\": 2, \"entropy_coef\": 0.0001, \"num_bins\": 101, \"vmin\": -10, \"vmax\": 10, \"model_size\": \"???\", \"num_enc_layers\": 2, \"enc_dim\": 256, \"num_channels\": 32, \"mlp_dim\": 512, \"latent_dim\": 512, \"task_dim\": 96, \"num_q\": 5, \"dropout\": 0.01, \"simnorm_dim\": 8, \"wandb_project\": \"???\", \"wandb_entity\": \"???\", \"wandb_silent\": false, \"disable_wandb\": true, \"save_csv\": true, \"save_video\": true, \"save_agent\": true, \"seed\": 1, \"work_dir\": \"???\", \"task_title\": \"???\", \"multitask\": \"???\", \"tasks\": \"???\", \"obs_shape\": \"???\", \"action_dim\": \"???\", \"episode_length\": \"???\", \"obs_shapes\": \"???\", \"action_dims\": \"???\", \"episode_lengths\": \"???\", \"seed_steps\": \"???\", \"bin_size\": \"???\", \"pad_to_shape\": [115]}}\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(\"/home/bsud/distill-act-datasets/datasets/myo5-easy/myo-key-turn/myo-key-turn_482.hdf5\") as f:\n",
    "    print(\"attrs \", f['data'].attrs['env_args'])\n",
    "    env_args = json.loads(f['data'].attrs['env_args'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "env_args['env_kwargs']['pad_to_shape'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add `task_id` to dataset\n",
    "```python\n",
    "ckpt_dir = Path(\"/home/krishnans/ngc/tdmpc2/ckpts/myosuite\")\n",
    "data_dir = Path(\"/home/krishnans/multi_task_experts/datasets/myo10/\")\n",
    "for task in list(MYOSUITE_TASKS.keys()):\n",
    "    task_name = \"-\".join([task.split(\"-\")[0], \"hand\"] + task.split(\"-\")[1:])\n",
    "    ckpt = ckpt_dir / f\"{task_name}-1.pt\" \n",
    "    overrides = [\"hydra/launcher=basic\"]\n",
    "    overrides.append(f\"task={task}\")\n",
    "    overrides.append(f\"checkpoint={str(ckpt.resolve())}\")\n",
    "\n",
    "    with hydra.initialize():\n",
    "        cfg = hydra.compose(\"config.yaml\", overrides=overrides)\n",
    "\n",
    "    dataset_path = list(data_dir.rglob(f\"{task}_*.hdf5\"))[0]\n",
    "    assert dataset_path.exists()\n",
    "    with h5py.File(str(dataset_path), \"a\") as f:\n",
    "        print(f\"writing task_id to dataset: {str(dataset_path)}\") \n",
    "        for demo in f[\"data\"].keys():\n",
    "            f.create_dataset(f\"data/{demo}/obs/task_id\", data=np.repeat(task_keys.index(task), len(f[\"data\"][demo][\"obs\"][\"vec_obs\"])))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: could not load d4rl environments! \n",
      "Missing path to your environment variable. \n",
      "Current values LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "Please add following line to .bashrc:\n",
      "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/bsud/.mujoco/mujoco210/bin\n",
      "Successfully imported MyoSuiteWrapper\n",
      "class is  <class 'robomimic.envs.env_gym.EnvMyo'>\n",
      "\u001b[36m    MyoSuite: A contact-rich simulation suite for musculoskeletal motor control\n",
      "        Vittorio Caggiano, Huawei Wang, Guillaume Durandau, Massimo Sartori, Vikash Kumar\n",
      "        L4DC-2019 | https://sites.google.com/view/myosuite\n",
      "    \u001b[0m\n",
      "Created environment with name myoHandKeyTurnFixed-v0\n",
      "Action size is 39\n",
      "\u001b[33mROBOMIMIC WARNING(\n",
      "    No environment version found in dataset!\n",
      "    Cannot verify if dataset and installed environment versions match\n",
      ")\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = EnvUtils.create_env_from_metadata(env_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Loaded Config =============\n",
      "{\n",
      "    \"algo_name\": \"bc\",\n",
      "    \"experiment\": {\n",
      "        \"name\": \"test\",\n",
      "        \"validate\": false,\n",
      "        \"logging\": {\n",
      "            \"terminal_output_to_txt\": true,\n",
      "            \"log_tb\": true,\n",
      "            \"log_wandb\": false,\n",
      "            \"wandb_proj_name\": \"debug\"\n",
      "        },\n",
      "        \"mse\": {\n",
      "            \"enabled\": false,\n",
      "            \"every_n_epochs\": 50,\n",
      "            \"on_save_ckpt\": true,\n",
      "            \"num_samples\": 20,\n",
      "            \"visualize\": true\n",
      "        },\n",
      "        \"save\": {\n",
      "            \"enabled\": true,\n",
      "            \"every_n_seconds\": null,\n",
      "            \"every_n_epochs\": 50,\n",
      "            \"epochs\": [],\n",
      "            \"on_best_validation\": false,\n",
      "            \"on_best_rollout_return\": false,\n",
      "            \"on_best_rollout_success_rate\": true\n",
      "        },\n",
      "        \"epoch_every_n_steps\": 100,\n",
      "        \"validation_epoch_every_n_steps\": 10,\n",
      "        \"env\": null,\n",
      "        \"additional_envs\": null,\n",
      "        \"render\": false,\n",
      "        \"render_video\": true,\n",
      "        \"keep_all_videos\": false,\n",
      "        \"video_skip\": 5,\n",
      "        \"rollout\": {\n",
      "            \"enabled\": false,\n",
      "            \"n\": 50,\n",
      "            \"horizon\": 400,\n",
      "            \"rate\": 50,\n",
      "            \"warmstart\": 0,\n",
      "            \"terminate_on_success\": true,\n",
      "            \"batched\": false,\n",
      "            \"num_batch_envs\": 5\n",
      "        },\n",
      "        \"env_meta_update_dict\": {},\n",
      "        \"ckpt_path\": null\n",
      "    },\n",
      "    \"train\": {\n",
      "        \"data\": [\n",
      "            {\n",
      "                \"path\": \"/home/bsud/distill-act-datasets/datasets/myo5-easy/myo-key-turn/myo-key-turn_482.hdf5\"\n",
      "            }\n",
      "        ],\n",
      "        \"output_dir\": \"../bc_trained_models\",\n",
      "        \"num_data_workers\": 0,\n",
      "        \"hdf5_cache_mode\": \"all\",\n",
      "        \"hdf5_use_swmr\": true,\n",
      "        \"hdf5_load_next_obs\": false,\n",
      "        \"hdf5_normalize_obs\": false,\n",
      "        \"hdf5_filter_key\": null,\n",
      "        \"hdf5_validation_filter_key\": null,\n",
      "        \"seq_length\": 1,\n",
      "        \"pad_seq_length\": true,\n",
      "        \"frame_stack\": 1,\n",
      "        \"pad_frame_stack\": true,\n",
      "        \"dataset_keys\": [\n",
      "            \"action\"\n",
      "        ],\n",
      "        \"action_keys\": [\n",
      "            \"action\"\n",
      "        ],\n",
      "        \"action_config\": {\n",
      "            \"action\": {\n",
      "                \"type\": \"continuous\",\n",
      "                \"dim\": 22\n",
      "            }\n",
      "        },\n",
      "        \"goal_mode\": null,\n",
      "        \"cuda\": true,\n",
      "        \"batch_size\": 100,\n",
      "        \"num_epochs\": 2000,\n",
      "        \"seed\": 1,\n",
      "        \"max_grad_norm\": null,\n",
      "        \"data_format\": \"robomimic\",\n",
      "        \"load_env_meta\": false,\n",
      "        \"shuffled_obs_key_groups\": null,\n",
      "        \"meta_ds_class\": \"MetaDataset\",\n",
      "        \"meta_ds_kwargs\": {}\n",
      "    },\n",
      "    \"algo\": {\n",
      "        \"optim_params\": {\n",
      "            \"policy\": {\n",
      "                \"optimizer_type\": \"adam\",\n",
      "                \"learning_rate\": {\n",
      "                    \"initial\": 0.0001,\n",
      "                    \"decay_factor\": 0.1,\n",
      "                    \"epoch_schedule\": [],\n",
      "                    \"scheduler_type\": \"multistep\"\n",
      "                },\n",
      "                \"regularization\": {\n",
      "                    \"L2\": 0.0\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"loss\": {\n",
      "            \"l2_weight\": 1.0,\n",
      "            \"l1_weight\": 0.0,\n",
      "            \"cos_weight\": 0.0\n",
      "        },\n",
      "        \"actor_layer_dims\": [\n",
      "            1024,\n",
      "            1024\n",
      "        ],\n",
      "        \"gaussian\": {\n",
      "            \"enabled\": false,\n",
      "            \"fixed_std\": false,\n",
      "            \"init_std\": 0.1,\n",
      "            \"min_std\": 0.01,\n",
      "            \"std_activation\": \"softplus\",\n",
      "            \"low_noise_eval\": true\n",
      "        },\n",
      "        \"gmm\": {\n",
      "            \"enabled\": false,\n",
      "            \"num_modes\": 5,\n",
      "            \"min_std\": 0.0001,\n",
      "            \"std_activation\": \"softplus\",\n",
      "            \"low_noise_eval\": true\n",
      "        },\n",
      "        \"vae\": {\n",
      "            \"enabled\": false,\n",
      "            \"latent_dim\": 14,\n",
      "            \"latent_clip\": null,\n",
      "            \"kl_weight\": 1.0,\n",
      "            \"decoder\": {\n",
      "                \"is_conditioned\": true,\n",
      "                \"reconstruction_sum_across_elements\": false\n",
      "            },\n",
      "            \"prior\": {\n",
      "                \"learn\": false,\n",
      "                \"is_conditioned\": false,\n",
      "                \"use_gmm\": false,\n",
      "                \"gmm_num_modes\": 10,\n",
      "                \"gmm_learn_weights\": false,\n",
      "                \"use_categorical\": false,\n",
      "                \"categorical_dim\": 10,\n",
      "                \"categorical_gumbel_softmax_hard\": false,\n",
      "                \"categorical_init_temp\": 1.0,\n",
      "                \"categorical_temp_anneal_step\": 0.001,\n",
      "                \"categorical_min_temp\": 0.3\n",
      "            },\n",
      "            \"encoder_layer_dims\": [\n",
      "                300,\n",
      "                400\n",
      "            ],\n",
      "            \"decoder_layer_dims\": [\n",
      "                300,\n",
      "                400\n",
      "            ],\n",
      "            \"prior_layer_dims\": [\n",
      "                300,\n",
      "                400\n",
      "            ]\n",
      "        },\n",
      "        \"rnn\": {\n",
      "            \"enabled\": false,\n",
      "            \"horizon\": 10,\n",
      "            \"hidden_dim\": 400,\n",
      "            \"rnn_type\": \"LSTM\",\n",
      "            \"num_layers\": 2,\n",
      "            \"open_loop\": false,\n",
      "            \"kwargs\": {\n",
      "                \"bidirectional\": false\n",
      "            }\n",
      "        },\n",
      "        \"transformer\": {\n",
      "            \"enabled\": false,\n",
      "            \"context_length\": 10,\n",
      "            \"embed_dim\": 512,\n",
      "            \"num_layers\": 6,\n",
      "            \"num_heads\": 8,\n",
      "            \"emb_dropout\": 0.1,\n",
      "            \"attn_dropout\": 0.1,\n",
      "            \"block_output_dropout\": 0.1,\n",
      "            \"sinusoidal_embedding\": false,\n",
      "            \"activation\": \"gelu\",\n",
      "            \"supervise_all_steps\": false,\n",
      "            \"nn_parameter_for_timesteps\": true,\n",
      "            \"pred_future_acs\": false,\n",
      "            \"causal\": true\n",
      "        },\n",
      "        \"language_conditioned\": false\n",
      "    },\n",
      "    \"observation\": {\n",
      "        \"modalities\": {\n",
      "            \"obs\": {\n",
      "                \"low_dim\": [\n",
      "                    \"vec_obs\"\n",
      "                ],\n",
      "                \"rgb\": [\n",
      "                    \"fixed_camera\"\n",
      "                ],\n",
      "                \"depth\": [],\n",
      "                \"scan\": []\n",
      "            },\n",
      "            \"goal\": {\n",
      "                \"low_dim\": [],\n",
      "                \"rgb\": [],\n",
      "                \"depth\": [],\n",
      "                \"scan\": []\n",
      "            }\n",
      "        },\n",
      "        \"encoder\": {\n",
      "            \"low_dim\": {\n",
      "                \"core_class\": null,\n",
      "                \"core_kwargs\": {},\n",
      "                \"obs_randomizer_class\": null,\n",
      "                \"obs_randomizer_kwargs\": {}\n",
      "            },\n",
      "            \"rgb\": {\n",
      "                \"core_class\": \"VisualCore\",\n",
      "                \"core_kwargs\": {\n",
      "                    \"feature_dimension\": 64,\n",
      "                    \"backbone_class\": \"ResNet18Conv\",\n",
      "                    \"backbone_kwargs\": {\n",
      "                        \"pretrained\": false,\n",
      "                        \"input_coord_conv\": false\n",
      "                    },\n",
      "                    \"pool_class\": \"SpatialSoftmax\",\n",
      "                    \"pool_kwargs\": {\n",
      "                        \"num_kp\": 32,\n",
      "                        \"learnable_temperature\": false,\n",
      "                        \"temperature\": 1.0,\n",
      "                        \"noise_std\": 0.0\n",
      "                    }\n",
      "                },\n",
      "                \"obs_randomizer_class\": null,\n",
      "                \"obs_randomizer_kwargs\": {}\n",
      "            },\n",
      "            \"depth\": {\n",
      "                \"core_class\": \"VisualCore\",\n",
      "                \"core_kwargs\": {},\n",
      "                \"obs_randomizer_class\": null,\n",
      "                \"obs_randomizer_kwargs\": {}\n",
      "            },\n",
      "            \"scan\": {\n",
      "                \"core_class\": \"ScanCore\",\n",
      "                \"core_kwargs\": {},\n",
      "                \"obs_randomizer_class\": null,\n",
      "                \"obs_randomizer_kwargs\": {}\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"meta\": {\n",
      "        \"hp_base_config_file\": null,\n",
      "        \"hp_keys\": [],\n",
      "        \"hp_values\": []\n",
      "    }\n",
      "}\n",
      "\n",
      "============= Initialized Observation Utils with Obs Spec =============\n",
      "\n",
      "using obs modality: low_dim with keys: ['vec_obs']\n",
      "using obs modality: rgb with keys: ['fixed_camera']\n",
      "using obs modality: depth with keys: []\n",
      "using obs modality: scan with keys: []\n",
      "network device  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Loaded Policy =============\n",
      "ObservationKeyToModalityDict: action not found, adding action to mapping with assumed low_dim modality!\n",
      "BC (\n",
      "  ModuleDict(\n",
      "    (policy): ActorNetwork(\n",
      "        action_dim=39\n",
      "  \n",
      "        encoder=ObservationGroupEncoder(\n",
      "            group=obs\n",
      "            ObservationEncoder(\n",
      "                Key(\n",
      "                    name=fixed_camera\n",
      "                    shape=[3, 64, 64]\n",
      "                    modality=rgb\n",
      "                    randomizer=ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    net=VisualCore(\n",
      "                      input_shape=[3, 64, 64]\n",
      "                      output_shape=[64]\n",
      "                      backbone_net=ResNet18Conv(input_channel=3, input_coord_conv=False)\n",
      "                      pool_net=SpatialSoftmax(num_kp=32, temperature=1.0, noise=0.0)\n",
      "                    )\n",
      "                    sharing_from=None\n",
      "                )\n",
      "                Key(\n",
      "                    name=vec_obs\n",
      "                    shape=[93]\n",
      "                    modality=low_dim\n",
      "                    randomizer=ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    net=None\n",
      "                    sharing_from=None\n",
      "                )\n",
      "                output_shape=[157]\n",
      "            )\n",
      "        )\n",
      "  \n",
      "        mlp=MLP(\n",
      "            input_dim=157\n",
      "            output_dim=1024\n",
      "            layer_dims=[1024]\n",
      "            layer_func=Linear\n",
      "            dropout=None\n",
      "            act=ReLU\n",
      "            output_act=ReLU\n",
      "        )\n",
      "  \n",
      "        decoder=ObservationDecoder(\n",
      "            Key(\n",
      "                name=action\n",
      "                shape=(39,)\n",
      "                modality=low_dim\n",
      "                net=(Linear(in_features=1024, out_features=39, bias=True))\n",
      "            )\n",
      "        )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = \"/home/bsud/multi_task_experts/robomimic/bc_trained_models/test/20240622210218/models/model_epoch_1950.pth\"\n",
    "\n",
    "policy, ckpt_dict = FileUtils.policy_from_checkpoint(\n",
    "    ckpt_path=ckpt_path, \n",
    "    device='cuda:0', \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_obs_dict(obs, obs_keys, env, device='cuda'):\n",
    "    obs_dict = {}\n",
    "    if hasattr(env, 'task'):\n",
    "        env_obs_dict = env.task.obs_dict\n",
    "    elif hasattr(env, 'obs_dict'):\n",
    "        env_obs_dict = env.obs_dict\n",
    "    else:\n",
    "        # handle myodex envs \n",
    "        env_obs_dict = {k: torch.as_tensor(obs[k], device=device) for k in obs_keys}\n",
    "\n",
    "    for k in obs_keys:\n",
    "        if \"camera\" in k and env_obs_dict[k].shape[-1] == 3:\n",
    "            if len(env_obs_dict[k].shape) == 4:\n",
    "                obs_dict[k] = env_obs_dict[k].permute(0, 3, 1, 2)\n",
    "            else:\n",
    "                obs_dict[k] = env_obs_dict[k].permute(2, 0, 1)[None]\n",
    "        else:\n",
    "            if len(env_obs_dict[k].shape) == 1:\n",
    "                obs_dict[k] = env_obs_dict[k][None]\n",
    "            else:\n",
    "                obs_dict[k] = env_obs_dict[k]\n",
    "            \n",
    "    return obs_dict\n",
    "            \n",
    "def rollout(policy, env, horizon, render=False, video_writer=None, video_skip=5, camera_names=None, device='cuda'):\n",
    "    \"\"\"\n",
    "    Helper function to carry out rollouts. Supports on-screen rendering, off-screen rendering to a video, \n",
    "    and returns the rollout trajectory.\n",
    "    Args:\n",
    "        policy (instance of RolloutPolicy): policy loaded from a checkpoint\n",
    "        env (instance of EnvBase): env loaded from a checkpoint or demonstration metadata\n",
    "        horizon (int): maximum horizon for the rollout\n",
    "        render (bool): whether to render rollout on-screen\n",
    "        video_writer (imageio writer): if provided, use to write rollout to video\n",
    "        video_skip (int): how often to write video frames\n",
    "        camera_names (list): determines which camera(s) are used for rendering. Pass more than\n",
    "            one to output a video with multiple camera views concatenated horizontally.\n",
    "    Returns:\n",
    "        stats (dict): some statistics for the rollout - such as return, horizon, and task success\n",
    "    \"\"\"\n",
    "    # assert isinstance(env, EnvBase)\n",
    "    assert isinstance(policy, RolloutPolicy)\n",
    "    assert not (render and (video_writer is not None))\n",
    "\n",
    "    policy.start_episode()\n",
    "    obs = env.reset()\n",
    "    obs_keys = set(policy.policy.nets.policy.obs_shapes.keys())\n",
    "    # state_dict = env.get_state()\n",
    "\n",
    "    # hack that is necessary for robosuite tasks for deterministic action playback\n",
    "    # obs = env.reset_to(state_dict)\n",
    "\n",
    "    results = {}\n",
    "    video_count = 0  # video frame counter\n",
    "    total_reward = 0.\n",
    "    try:\n",
    "        for step_i in range(horizon):\n",
    "            obs_dict = get_obs_dict(obs, obs_keys, env, device=device)\n",
    "            print(\"got obs dict\")\n",
    "            # get action from policy\n",
    "            act = policy(ob=obs_dict, batched=True)\n",
    "            print(\"ran policy\")\n",
    "\n",
    "            # play action\n",
    "            next_obs, r, done, info = env.step(act[0])\n",
    "\n",
    "            # compute reward\n",
    "            total_reward += r\n",
    "            success = info[\"success\"] # env.is_success()[\"task\"]\n",
    "\n",
    "            # visualization\n",
    "            if video_writer is not None:\n",
    "                if video_count % video_skip == 0:\n",
    "                    video_img = []\n",
    "                    for cam_name in camera_names:\n",
    "                        video_img.append(obs_dict[cam_name].cpu().numpy()[0])\n",
    "                    video_img = np.concatenate(video_img, axis=1) # concatenate horizontally\n",
    "                    video_writer.append_data(video_img)\n",
    "                video_count += 1\n",
    "\n",
    "            # break if done or if success\n",
    "            if done or success:\n",
    "                break\n",
    "\n",
    "            # update for next iter\n",
    "            obs = deepcopy(next_obs)\n",
    "            # state_dict = env.get_state()\n",
    "\n",
    "    except env.rollout_exceptions as e:\n",
    "        print(\"WARNING: got rollout exception {}\".format(e))\n",
    "\n",
    "    stats = dict(Return=total_reward, Horizon=(step_i + 1), Success_Rate=float(success))\n",
    "\n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got obs dict\n",
      "prepared obs\n",
      "policy is  BC (\n",
      "  ModuleDict(\n",
      "    (policy): ActorNetwork(\n",
      "        action_dim=39\n",
      "  \n",
      "        encoder=ObservationGroupEncoder(\n",
      "            group=obs\n",
      "            ObservationEncoder(\n",
      "                Key(\n",
      "                    name=fixed_camera\n",
      "                    shape=[3, 64, 64]\n",
      "                    modality=rgb\n",
      "                    randomizer=ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    net=VisualCore(\n",
      "                      input_shape=[3, 64, 64]\n",
      "                      output_shape=[64]\n",
      "                      backbone_net=ResNet18Conv(input_channel=3, input_coord_conv=False)\n",
      "                      pool_net=SpatialSoftmax(num_kp=32, temperature=1.0, noise=0.0)\n",
      "                    )\n",
      "                    sharing_from=None\n",
      "                )\n",
      "                Key(\n",
      "                    name=vec_obs\n",
      "                    shape=[93]\n",
      "                    modality=low_dim\n",
      "                    randomizer=ModuleList(\n",
      "                      (0): None\n",
      "                    )\n",
      "                    net=None\n",
      "                    sharing_from=None\n",
      "                )\n",
      "                output_shape=[157]\n",
      "            )\n",
      "        )\n",
      "  \n",
      "        mlp=MLP(\n",
      "            input_dim=157\n",
      "            output_dim=1024\n",
      "            layer_dims=[1024]\n",
      "            layer_func=Linear\n",
      "            dropout=None\n",
      "            act=ReLU\n",
      "            output_act=ReLU\n",
      "        )\n",
      "  \n",
      "        decoder=ObservationDecoder(\n",
      "            Key(\n",
      "                name=action\n",
      "                shape=(39,)\n",
      "                modality=low_dim\n",
      "                net=(Linear(in_features=1024, out_features=39, bias=True))\n",
      "            )\n",
      "        )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "nets  ActorNetwork(\n",
      "    action_dim=39\n",
      "\n",
      "    encoder=ObservationGroupEncoder(\n",
      "        group=obs\n",
      "        ObservationEncoder(\n",
      "            Key(\n",
      "                name=fixed_camera\n",
      "                shape=[3, 64, 64]\n",
      "                modality=rgb\n",
      "                randomizer=ModuleList(\n",
      "                  (0): None\n",
      "                )\n",
      "                net=VisualCore(\n",
      "                  input_shape=[3, 64, 64]\n",
      "                  output_shape=[64]\n",
      "                  backbone_net=ResNet18Conv(input_channel=3, input_coord_conv=False)\n",
      "                  pool_net=SpatialSoftmax(num_kp=32, temperature=1.0, noise=0.0)\n",
      "                )\n",
      "                sharing_from=None\n",
      "            )\n",
      "            Key(\n",
      "                name=vec_obs\n",
      "                shape=[93]\n",
      "                modality=low_dim\n",
      "                randomizer=ModuleList(\n",
      "                  (0): None\n",
      "                )\n",
      "                net=None\n",
      "                sharing_from=None\n",
      "            )\n",
      "            output_shape=[157]\n",
      "        )\n",
      "    )\n",
      "\n",
      "    mlp=MLP(\n",
      "        input_dim=157\n",
      "        output_dim=1024\n",
      "        layer_dims=[1024]\n",
      "        layer_func=Linear\n",
      "        dropout=None\n",
      "        act=ReLU\n",
      "        output_act=ReLU\n",
      "    )\n",
      "\n",
      "    decoder=ObservationDecoder(\n",
      "        Key(\n",
      "            name=action\n",
      "            shape=(39,)\n",
      "            modality=low_dim\n",
      "            net=(Linear(in_features=1024, out_features=39, bias=True))\n",
      "        )\n",
      "    )\n",
      ")\n",
      "in actor forward\n",
      "in mimo mlp forward\n",
      "obs group  obs\n"
     ]
    }
   ],
   "source": [
    "# env.rollout_exceptions = ()\n",
    "stats = rollout(\n",
    "    policy=policy, \n",
    "    env=env, \n",
    "    horizon=100, \n",
    "    render=False, \n",
    "    video_writer=None, \n",
    "    video_skip=5, \n",
    "    camera_names=[\"hand_camera\"]\n",
    ")\n",
    "print(stats)\n",
    "# video_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
